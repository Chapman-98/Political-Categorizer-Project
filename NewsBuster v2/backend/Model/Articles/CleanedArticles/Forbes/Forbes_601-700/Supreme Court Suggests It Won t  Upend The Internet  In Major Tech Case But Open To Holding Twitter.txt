ToplineThe Supreme Court appears poised to protect social media companies from being held legally liable under a controversial 27-year-old law for third-party content their algorithms recommend, but may be more willing to hold them accountable under anti-terrorism laws, as the high court heardtwo caseson Tuesday and Wednesday that tech giants warned could have wide-reaching impacts <figure><figcaption>The U S  Supreme Court Building in Washington, D C Getty Images</figcaption></figure>Key FactsThe Supreme Court heard oral arguments Tuesday in a case considering whether YouTube and parent company Google could be held liable for its algorithm recommending ISIS recruitment videos to potential supporters following the 2015 Paris terrorism attacks, and heard a separate case Wednesday that dealt with similar questions against Twitter, Facebook and Google stemming from a 2017 terrorist attack in Turkey The first case dealt withSection 230of the Communications Decency Act of 1996, which shields Internet companies from being sued over third-party content posted on their platforms, and justices seemed largely uninterested in taking action to narrow the statute and hold platforms liable for content their algorithm recommends  These are not like the nine greatest experts on the Internet,  Justice Elena Kagan said about the justices, suggesting the issue of Section 230 should be left up to Congress and that there s  a lot of uncertainty  should the court rule against Google, after tech companies warned such a ruling could result in widespread chaos if companies could be sued for any objectionable content posted online  Isn t it better to keep [Section 230] the way it is, for us, and to put the burden on Congress to change  it, Justice Brett Kavanaugh asked during Tuesday s oral arguments, while even Justice Clarence Thomas who previously suggested the court should take up Section 230 said algorithms are  neutral  and questioned the petitioners arguing that recommending ISIS videos was different to  present[ing] cooking videos to people who are interested in cooking  or  racing videos to people who are interested in racing  The second case asked if Twitter could be held liable under the Anti-Terrorism Act, which allows lawsuits against anyone who  aids and abets  an act of international terrorism on Wednesday, justices seemed more unsure of absolving the company of blame for ISIS content on its platform under that law, with Kagan suggesting Twitter was  providing your service to those people, with the explicit knowledge that those people are using it to advance terrorism  Justice Samuel Alito said that while Twitter could not be held legally liable on criminal charges, the different standard under the anti-terrorism act  makes it somewhat difficult  to determine whether the company bears responsibility, and Kagan questioned how the case differed from othercasesin which banks have been held liable after terrorists used their services ContraOther justices expressed more willingness to rule in Twitter s favor in the case heard Wednesday, so it still remains to be seen exactly which way the court will rule  Justice Neil Gorsuch suggested the case didn t match up with the anti-terrorism statute, which suggests that people can only be held liable for aiding and abetting specific people who commit acts of terrorism, rather than general terrorism events  (The lawsuit does not accuse Twitter of helping any specific people who committed the terrorist attack )  I m struggling with how your complaint lines up  with the statute, Gorsuch told the attorney suing Twitter What To Watch ForThe court will issue rulings in the two cases by the time its term wraps up in late June or early July  If the court dismisses the Twitter case heard Wednesday, it s likely they ll be able to throw out the Google case by extension without issuing a sweeping ruling on Section 230 that could have broader implications, Justice Amy Coney Barrett suggested Tuesday   If you lose tomorrow, do we even have to reach the Section 230 question here?  Barrett asked attorney Eric Schnapper, who argued both cases against the tech companies What We Don t KnowWhat impact the court s ruling would have  If the Supreme Court were to rule against tech companies in the Google case and issue a decision that narrowed Section 230, tech companies including Google, Meta, Twitter, Microsoft, Yelp, Reddit, Craigslist and Wikipedia warned in filings to the court that the results could be disastrous for the Internet  Platforms would be forced to either remove any content that could possibly be considered objectionable for fear of legal liability, or take the opposite approach and leave everything up, even dangerous content, platforms argued and targeting recommendation algorithms could result in content not being able to be sorted as users need  If people can now sue social media companies  by targeting how websites sort content or trying to hold users liable for liking or sharing articles, the internet would devolve into a disorganized mess and a litigation minefield,  Google argued in a filing  Opponents, however, have argued that tech companies need reining in and the current broadness of Section 230 gives them too much leeway, suggesting narrowing the statute could force platforms to be more aggressive in policing problematic content  In the case heard Wednesday, tech companies have warned that a ruling against them could result in wide-ranging implications for tech giants being subject to legal liability, but also other businesses and organizations whose services terrorists may use, including potentially humanitarian groups operating in countries like Syria TangentJustices Tuesday also repeatedly expressed their confusion with the petitioners  argument being made against the tech companies   I'm afraid I'm completely confused by whatever argument you're making at the present time,  Alito told Schnapper, while Justice Ketanji Brown Jackson said she was also  thoroughly confused  by a line of argument  After the Biden Administration made its opening argument in support of ruling against the tech companies, Thomas responded,  Well, I m still confused  Key BackgroundThe two tech cases were brought against social media companies by families of victims in the 2015 and 2017 terrorist attacks in Paris and Turkey, respectively  The Ninth Circuit Court of Appeals heard both cases together but came todifferent conclusionsin 2021, finding that Section 230 did not apply in the Google case and social media companies were free from liability, but also that companies could be held liable under anti-terrorism laws  The Supreme Court taking up the two cases came as the regulation of tech giants and the proliferation of controversial content on their platforms has come under greater scrutiny from both sides of the political aisle, and there had been speculation that the 6-3 conservative court could rail against Section 230 after GOP lawmakers have repeatedly taken aim at it  The statute has become increasingly controversial as Republicans have targeted tech companies for their purported bias against conservatives, and Sen  Ted Cruz (R-Texas) and other lawmakersarguedin a filing to the Supreme Court in the Google case that social media companies have used the broad interpretation of the statute to  [not be] shy about restricting access and removing content based on the politics of the speaker  Further ReadingShould YouTube, Twitter Be More Responsible For Dangerous Content? Supreme Court Considers Tech Critics(Forbes)The Supreme Court takes up Section 230(Brookings)Everything you need to know about Section 230(The Verge)These 26 words  created the internet   Now the Supreme Court may be coming for them(CNN)