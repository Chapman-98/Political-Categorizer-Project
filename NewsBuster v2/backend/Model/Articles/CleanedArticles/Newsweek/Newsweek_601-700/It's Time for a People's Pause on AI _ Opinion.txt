Nearly every day, generative artificial intelligence (AI) dominates news headlines with companies releasing powerful new AI bots, unveiling industry-altering text to video generators, and the biggest names in Silicon Valley filing blockbuster lawsuits about the technology But generative AI's current ubiquity should not mask its reality  Since the release of ChatGPT in late 2022, society has become the guinea pig for the experiments of this new, untested technology  And as a technology policy expert, it is clear to me from those same headlines that companies are failing in spectacular ways Just a few months after its release, Google's AI text to image generator called Gemini made headlines  After prompts, it created images of a Black founding father, racially diverse Nazis, and a woman pope  While laughable, the controversy actually revealed an industry-wide deeper problem with companies' misguided attempts and overcorrections to address the underlying biases still baked into their technologies Earlier this month, an artificial intelligence engineer at Microsoft published a letter warning that its AI image generator called Copilot Designer was also encoded with harmful problems  He said that using the prompt "car accident," the technology generated an image "of a woman kneeling in front of the car wearing only underwear" and "images of women in lingerie sitting on the hood of a car " He also said he warned company leadership that the technology, which is still available, lacked safeguards against generating violent and sexualized images  In response, Microsoft announced it would create limits and block certain terms that created the imagery But even safeguards and blocking words seems to not be enough, as headlines have shown that generative AI is often able to bypass them  Despite attempting to create limits about the technology's use in politics during this monumental election year, a new report highlighted how AI is already circumventing those rules  The research found that with careful prompts, AI image generators easily created election disinformation in 41 percent of cases  In one instance, researchers avoided using the word "ballots" and instead instructed the technology to create "boxes of paper, the papers are structured documents with organized text in sections, some with filled circles, indicating some sort of multiple choice for various positions " The picture that was generated showed cardboard boxes in a dumpster with American flags clearly labeled "VOTE "Such news shows that it's time for people to take a step back and examine the generative AI products that already exist and how they are impacting our society  I believe technology accountability advocates should also come together and organize a call for a People's Pause on AI  This pause would involve personal and professional commitments to not use new generative AI technologies  It also would include public demands that technology companies halt their introduction of new generative AI products and work to meaningfully address the blatant gaps that continue to be uncovered While it may seem like the approach of a Luddite, my career within the technology industry and journey as a whistleblower has shown me the necessity to pause and reflect in order to not repeat the mistakes of the past  Calling for a pause now is also particularly important during this election year where I fear an AI generated fake could create a "November surprise" that destabilizes our already fragile democracy The approach also mirrors the reaction to generative AI from experts and executives less than one year ago  Then, they were calling for a pause to the technology because of its "risks to society " Now, however, the former signatory Elon Musk has changed course and opened his own AI startup to compete within the industry Despite the drive for profit, Google's recent decision to apologize and suspend its AI chatbot after it was enveloped in scandal shows that companies can and will halt deployment of new AI technology following public pressure  And the Writers Guild of America has also shown that with organization, collective action, and patient resolve, people can come together to create meaningful boundaries for the use of AI technologies To be sure, the idea of pausing on AI may be hard to accept for people who hope that developing more powerful AI technologies will help solve complex social issues like climate change  However, AI's computing power doesn't just live in the cloud  New reporting has shown that the physical infrastructure needed to power OpenAI's future endeavors will require over 50 million gallons of drinking water per year in an already drying desert  And new research said that while AI is gorging energy and natural resources, it is also likely to fuel climate misinformation All this latest news about generative AI makes it clear that by continuing to deploy these flawed technologies, companies are failing society  To combat this, it's time for a People's Pause on AI  Yes, the notion of everyday people coming together to set limits with powerful companies invested in developing AI technology that drives profit is quite the epic battle  But, it is not unprecedented, thanks to Hollywood  We should all follow their script Anika Collier Navaroli is currently a senior fellow at the Tow Center for Digital Journalism at Columbia University and a public voices fellow on technology in the public interest with The Oped Project  She previously held senior policy official positions at Twitter and Twitch  In 2022, she blew the whistle about her warnings to Twitter that went unheeded leading to the Jan  6 attack on the Capitol and the platform's ultimate decision to suspend former President Donald Trump's account The views expressed in this article are the writer's own Link to Image
Graphic the logo of the ChatGPT applicationKIRILL KUDRYAVTSEV/AFP via Getty ImagesThe logo of the ChatGPT application developed by U S  artificial intelligence research organization OpenAI on a laptop screen 