It’s Election Day Arizona elderly voters Maricopa County told phone local polling places closed due threats militia groups. Meanwhile, Miami, flurry photos videos social media show poll workers dumping ballots. phone calls Arizona videos Florida turn “deepfakes” created artificial intelligence tools. time local federal authorities figure dealing with, false information gone viral across country. simulated scenario part recent exercise New York gathered dozens former senior U.S. state officials, civil society leaders executives technology companies rehearse 2024 election. results sobering. “It jarring folks room see quickly handful types threats could spiral control really dominate election cycle,” said Miles Taylor, former senior Department Homeland Security official helped organize exercise Washington-based nonprofit Future US. Dubbed “The Deepfake Dilemma,” exercise illustrated AI-enabled tools threaten turbocharge spread false information already polarized society could sow chaos 2024 election, multiple participants told NBC News. Rather examining singular attack group hostile regime, exercise explored scenario array domestic foreign actors launching disinformation, exploiting rumors seizing political divisions. organizers participants war game spoke exclusively NBC News played out. said raised worrisome questions whether federal local officials — tech industry — prepared counter foreign domestic disinformation designed undermine public confidence election results. Current U.S. officials say privately share concerns state local election agencies hard-pressed keep election process track. exercise illustrated uncertainty surrounding roles federal state agencies tech firms seven months expected one divisive elections U.S. history. federal government ability detect AI deepfake? White House state election office publicly declare particular report false? Unlike natural disaster, government agencies work central command, America’s decentralized electoral system entering uncharted territory without clear sense who’s charge, said Nick Penniman, CEO Issue One, bipartisan organization promoting political reform election integrity. “Now, last years, America defend assaults elections domestic foreign forces. don’t infrastructure history scale we’ve never face threats severe past,” said Penniman, took part exercise. “We know hurricane eventually going hit elections,” said Penniman. exercise, “because patterns working together haven’t formed, people understood exactly coordinating others not.” mock “White House Situation Room” around long table, participants played assigned roles — including directors FBI, CIA Department Homeland Security — sifted alarming reports Arizona Florida numerous unconfirmed threats, including break-in postal processing center mail-in ballots. Conferring tech companies, players “government officials” struggled determine facts, spreading “deepfakes” government agencies respond. (MSNBC anchor Alex Witt also took part exercise, playing role president National Association Broadcasters.) exercise, unclear initially photos video poll workers tossing ballots Miami fake. images gone viral, partly bot-texting campaign Russia. Eventually, officials able establish whole episode staged enhanced artificial intelligence make look convincing. woman walks past "Vote Here" sign Miami Beach City Hall Miami Beach, Fla., Oct. 19, 2020. Eva Marie Uzcategui / AFP via Getty Images file cases, including fake calls Arizona voters, players hesitated make public announcement telling voters polling places safe ballots secure. Federal officials worried public statement would seen attempt boost chances President Joe Biden’s re-election. “There also lot debate uncertainty whether White House president engage,” Taylor said. “One big debates room whose job say something’s real fake,” said. “Is state-level election officials say we’ve determined there’s fake? private companies? White House?” Said Taylor, “That’s something think we’re also going see election cycle.” although war game imagined tech executives room federal officials, reality, communication federal government private firms counter foreign propaganda disinformation sharply diminished recent years. close cooperation among federal officials, tech companies researchers developed 2016 election unraveled due sustained Republican attacks Congress court rulings discouraging federal agencies consulting companies moderating online content. result potentially risky gap safeguarding 2024 election. State governments lack resources detect AI deepfake counter quickly accurate information, technology companies federal agencies wary taking leading role, former officials experts said. “Everybody’s terrified lawsuits ... accusations free speech suppression,” said Kathy Boockvar, former Pennsylvania secretary state, took part exercise. New York war game, plus similar sessions carried states, part wider effort try encourage communication tech executives government officials, said Taylor. world outside war game, social media platforms cut back teams moderate false election content, there’s sign companies ready pursue close cooperation government. State local election offices, meanwhile, face significant shortage experienced staff. wave physical cyber threats triggered record exodus election workers, leaving election agencies ill-prepared November. Concerned understaffed inexperienced state election agencies, coalition nonprofits good-government groups planning organize bipartisan, countrywide network former officials, technology specialists others help local authorities detect deepfakes real time respond accurate information. “We’re going best — independent federal government social media platforms — try fill gap,” said Penniman, whose organization involved election security effort. Boockvar, former secretary state, said hopes nonprofits act bridge tech companies federal government, helping maintain communication channels. largest AI tech firms say introducing safeguards products communicating government officials help bolster election security November vote. “Ahead upcoming elections, OpenAI put place policies prevent abuse, launched new features increase transparency around AI-generated content, developed partnerships connect people authoritative sources voting information,” said spokesperson. “We continue work alongside governments, industry partners, civil society toward shared goal protecting integrity elections around world.” internet, however, filled smaller generative-AI companies may abide rules, well open-source tools allow people build generative-AI programs. Voters cast ballots inside Museum Contemporary Art Arlington, Va., Nov. 8, 2022. Nathan Howard / Getty Images file FBI spokesperson declined comment hypothetical situation, said bureau’s Foreign Influence Task Force remains federal lead “for identifying, investigating, disrupting foreign malign influence operations targeting democratic institutions values inside United States.” U.S. Cybersecurity Infrastructure Security Agency said it’s working closely state local agencies protect country’s elections. “CISA proud continue stand shoulder shoulder state local election officials defend elections process range cyber, physical, operational security risks, include risk foreign influence operations,” said senior adviser Cait Conley. many room exercise, scenarios drove home need develop ambitious public education campaign help voters recognize deepfakes inoculate Americans coming onslaught foreign domestic disinformation. Future US groups holding talks Hollywood writers producers develop series public service videos help raise awareness phony video audio clips election campaign, according Evan Burfield, chief strategy officer Future US. public education campaigns efforts fail contain contagion disinformation potential violence, country could face unprecedented deadlock election. enough doubts raised transpired election, there’s danger outcome vote becomes “stalemate” clear winner, said Danny Crichton Lux Capital, venture capital firm focused emerging technologies, co-hosted exercise. enough things “go wrong people stuck polls, get draw,” Crichton said. “And worst-case scenario. ... don’t think system robust enough handle that.”